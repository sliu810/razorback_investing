{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-api-python-client google-auth google-auth-oauthlib google-auth-httplib2 \n",
    "# !pip install --upgrade google-auth-oauthlib\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and APIs\n",
    "import fetch_videos\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "# Ensure you have set your OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel Definitions and Setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily News Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify channel ID and name\n",
    "channel_id = fetch_videos.channels[\"CNBC_TV\"]  # Change this to the desired channel ID\n",
    "channel_name = fetch_videos.get_channel_name_by_id(channel_id, fetch_videos.channels)\n",
    "summary_file_name_today = f'summaries_{channel_name}_{fetch_videos.get_formated_date_today()}'\n",
    "summary_file_name_today_cvs = f'{summary_file_name_today}.csv'\n",
    "summary_file_name_today_html = f'{summary_file_name_today}.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 2 new videos to summaries_CNBC_TV_2024-08-21.csv.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## Fetch videos\n",
    "period_type = 'today'  # 'today', 'days', 'weeks', 'months'\n",
    "number = 1  # The 'today' setting does not use 'number', adjust if using other settings\n",
    "start_date, end_date = fetch_videos.get_date_range(period_type, number)\n",
    "df_videos_today = fetch_videos.fetch_videos(start_date, end_date, channel_id,summary_file_name_today_cvs)\n",
    "\n",
    "# ## Filter Vidoes by time\n",
    "# # Assume df_videos is your initial DataFrame loaded with video data\n",
    "# hour_range1 = '0-8'\n",
    "# hour_range2 = '8-10'\n",
    "# hour_range3 = '10-12'\n",
    "# hour_range4 = '12-14'\n",
    "# hour_range5 = '14-16'\n",
    "# hour_range6 = '16-24'\n",
    "\n",
    "# # Filter videos from the last 3 days\n",
    "# filtered_df = fetch_videos.filter_videos_by_date_and_time(df_videos_today, 'today', 1)\n",
    "# # fetch_videos.display_df(filtered_df)\n",
    "\n",
    "## Add transcripts\n",
    "df_videos_with_transcripts = fetch_videos.add_transcripts_to_df(df_videos_today)\n",
    "# fetch_videos.display_df(df_videos_with_transcripts,include_video_id=True,include_transcript=True)\n",
    "df_videos_with_transcripts.to_csv(summary_file_name_today_cvs, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assign Tasks: Get Summary\n",
    "task_summary = \"\"\"I would like you to summarize the transcript with the following instructions: \n",
    "First categorize the video content.The category should be one of the following: Crypto, Macro, Politics, Technology, Small Caps or Other. \n",
    "Then summarize the stocks that are mentioned in this video.\n",
    "Then provide key takeaways in a bullet point format.Please make sure don't miss anything about small cap, Nvidia, Tesla, Meta and Macro is mentioned in the transcript.\n",
    "Please print the summary in a human-readable format like the following: \n",
    "Category: Technology\n",
    "Stock mentioned: STOCK1, STOCK2, STOCK3\n",
    "Key takeaways:\n",
    "* takeaway 1\n",
    "* takeaway 2\n",
    "* takeaway 3\n",
    "\"\"\"\n",
    "# load df_videos_with_transcripts from CSV\n",
    "df_videos_with_transcripts = pd.read_csv(summary_file_name_today_cvs)\n",
    "\n",
    "# Get summaries for all transcripts\n",
    "df_summaries = fetch_videos.apply_tasks_on_all_transcripts(df_videos_with_transcripts, client, task_summary)\n",
    "\n",
    "# Save summaries to a CSV file\n",
    "df_summaries.to_csv(summary_file_name_today_cvs, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save summaries to an HTML file \n",
    "df_summaries = pd.read_csv(summary_file_name_today_cvs)\n",
    "html_content = fetch_videos.get_html_content_summary_only(df_summaries)\n",
    "# print(html_content)\n",
    "\n",
    "# Save the HTML content to an HTML file\n",
    "with open(summary_file_name_today_html, 'w') as file:\n",
    "    file.write(html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save titles and transcripts to a text file\n",
    "summary_file_name_today_txt = f'{summary_file_name_today}.txt'\n",
    "fetch_videos.save_videos_to_text(df_summaries, summary_file_name_today_txt,\"Title\", \"Summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text discussing small cap or Russell stocks is from the article titled \"Consumer spending environment remains tepid at best, says CFRA's Arun Sundaram.\" This article mentions small cap stocks such as Target, Walmart, Home Depot, Lowes, Amazon, Costco, and Macy's. It highlights that big box retailers like Walmart, Target, and Costco are performing well, with a focus on value, newness, and broad product assortment. It also notes that consumer spending remains selective, leaning towards big box retailers, and that promotions and discounts are impacting retail sales positively.\n"
     ]
    }
   ],
   "source": [
    "task2 = \"\"\"Please tell me anything discussed in the file about small cap or russell stocks. \n",
    "Please also provide which video or speaker side this\n",
    "\"\"\"\n",
    "with open(summary_file_name_today_txt, 'r') as file:\n",
    "    all_transcripts = file.read()\n",
    "summary = fetch_videos.apply_task(all_transcripts, client, task2)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI for all transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email sent successfully!\n"
     ]
    }
   ],
   "source": [
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "import pandas as pd\n",
    "import os\n",
    "import fetch_videos\n",
    "\n",
    "email_user = os.getenv('EMAIL_USER')\n",
    "email_password = os.getenv('EMAIL_PASSWORD')\n",
    "email_send1 = 'sliu810@gmail.com'\n",
    "email_send2 = 'zhengwang827@gmail.com'\n",
    "\n",
    "recipients = [email_send1, email_send2]\n",
    "# Set up the MIME\n",
    "message = MIMEMultipart()\n",
    "message['From'] = email_user\n",
    "message['To'] = email_send1\n",
    "message['Subject'] = f'summaries_{channel_name}_{fetch_videos.get_formated_date_today()}'\n",
    "\n",
    "# load df_summaries from disk and get the html content\n",
    "df_summaries = pd.read_csv(summary_file_name_today_cvs)\n",
    "html_content= fetch_videos.get_html_content_summary_only(df_summaries)\n",
    "\n",
    "# Attach the HTML content to the email\n",
    "message.attach(MIMEText(html_content, 'html'))\n",
    "\n",
    "# Function to send email\n",
    "def send_email():\n",
    "    try:\n",
    "        server = smtplib.SMTP('smtp-mail.outlook.com', 587)  # Outlook SMTP server\n",
    "        #server.set_debuglevel(1)  # Enable debugging output\n",
    "        server.starttls()\n",
    "        server.login(email_user, email_password)\n",
    "        text = message.as_string()\n",
    "        server.sendmail(email_user, recipients, text)\n",
    "        server.quit()\n",
    "        print(\"Email sent successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to send email: {e}\")\n",
    "\n",
    "# Send the email\n",
    "send_email()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Off Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript = fetch_videos.get_transcript('GabBf791bdY')\n",
    "# print(transcript)\n",
    "# # Example task\n",
    "# task2 = \"\"\"I would like you to summarize the text which describes Tesla FSD.\n",
    "# Please say in what senario FSD performed well and waht senario it didn't perform well.\n",
    "# Format like this:\n",
    "# Title: \n",
    "# Key takeaways:\n",
    "# * FSD performed well in ...\n",
    "# * FSD had some challenges in ....\n",
    "# Improvement over pervious version if any.\n",
    "# \"\"\"\n",
    "# task3 = \"\"\"could you print the transcript with two person speaking into a human readible format and maintain the original content?\"\"\"\n",
    "\n",
    "# summary = get_summary(transcript, client, task3)\n",
    "# print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_in_chunks(transcript, client, task, chunk_size=500):\n",
    "    \"\"\"\n",
    "    Generates summaries in chunks to avoid truncation.\n",
    "\n",
    "    Parameters:\n",
    "    - transcript (str): The full transcript text.\n",
    "    - client (object): The client to use for generating summaries.\n",
    "    - task (str): The task identifier for the summary generation.\n",
    "    - chunk_size (int): The maximum size of each chunk.\n",
    "\n",
    "    Returns:\n",
    "    - str: Combined summary of all chunks.\n",
    "    \"\"\"\n",
    "    import textwrap\n",
    "\n",
    "    # Split the transcript into chunks\n",
    "    chunks = textwrap.wrap(transcript, chunk_size)\n",
    "    full_summary = \"\"\n",
    "\n",
    "    for chunk in chunks:\n",
    "        summary = get_summary(chunk, client, task)\n",
    "        full_summary += summary + \"\\n\"\n",
    "\n",
    "    return full_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript = fetch_videos.get_transcript('I8JzsnZVylY')\n",
    "# print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task2 = \"\"\"I would like you to summarize the text which describes Tesla FSD.\n",
    "# Please say in what senario FSD performed well and waht senario it didn't perform well.\n",
    "# Format like this:\n",
    "# Title: \n",
    "# Key takeaways:\n",
    "# * FSD performed well in ...\n",
    "# * FSD had some challenges in ....\n",
    "# Improvement over pervious version if any.\n",
    "# \"\"\"\n",
    "# task3 = \"\"\"\"\"\"\n",
    "\n",
    "# # summary = fetch_videos.apply_task(transcript, client, task3)\n",
    "# print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
