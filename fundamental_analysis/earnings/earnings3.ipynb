{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b523e0a",
   "metadata": {},
   "source": [
    "# Earnings Call Transcript Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a323703",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148f9dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile requirements.txt\n",
    "# llama-index\n",
    "# llama-index-llms-huggingface\n",
    "# llama-index-embeddings-fastembed\n",
    "# fastembed\n",
    "# Unstructured[md]\n",
    "# chromadb\n",
    "# llama-index-vector-stores-chroma\n",
    "# llama-index-llms-groq\n",
    "# einops\n",
    "# accelerate\n",
    "# sentence-transformers\n",
    "# llama-index-llms-mistralai\n",
    "# llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9625ab2-71b6-4fd0-904e-42df80d3215f",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from helper import get_openai_api_key\n",
    "OPENAI_API_KEY = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3221a474-5817-4db2-af46-e029042a75a5",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20adaa26",
   "metadata": {},
   "source": [
    "## 1. Setup an agent over 3 papers\n",
    "\n",
    "We can create vector search and summary tools respectively for each of the 3 papers, which then result in 6 tools in total. These tools can then be made available to the agent worker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "342c0b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shop', 'low']\n",
      "['transcripts/shop.pdf', 'transcripts/low.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "root_path = \"transcripts\"\n",
    "file_name = []\n",
    "file_path = []\n",
    "for file in os.listdir(root_path):\n",
    "  if file.endswith(\".pdf\"):\n",
    "    file_name.append(file.split(\".\")[0])\n",
    "    file_path.append(os.path.join(root_path,file))\n",
    "#\n",
    "print(file_name)\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d8f3185-3221-4b00-bd38-41d36e4a3307",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_doc_tools\n",
    "from pathlib import Path\n",
    "\n",
    "papers_to_tools_dict = {}\n",
    "for name,filename in zip(file_name,file_path):\n",
    "  vector_tool,summary_tool = get_doc_tools(filename,name)\n",
    "  papers_to_tools_dict[name] = [vector_tool,summary_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e541bdd-14e1-41b6-81b5-b1bfda078d07",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "initial_tools = [t for f in file_name for t in papers_to_tools_dict[f]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bff58c52",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f2c6a9f",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(initial_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a124a438-5609-402e-8642-69d1088cb9ad",
   "metadata": {
    "height": 166,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "system_message = \"\"\" \\\n",
    "You are an agent designed to answer queries over a set of given earnings call transcripts reports.\n",
    "Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\n",
    "\"\"\"\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    initial_tools, \n",
    "    llm=llm, \n",
    "    system_prompt=system_message,\n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17409d4c-05a9-4bf4-b74f-75135fa3cb6b",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me about how shopify uses AI in their business (please use original words and as detailed as possible),and then tell me their initial results on using AI\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_shop with args: {\"input\": \"Shopify's use of AI in their business and their initial results\"}\n",
      "=== Function Output ===\n",
      "Shopify has utilized AI in their business to optimize marketing strategies, enhance customer acquisition, and improve customer engagement. Their AI-driven marketing systems have enabled them to maximize returns on existing channels and explore new ones effectively. By leveraging data analytics, Shopify has identified successful channels and capitalized on them, leading to increased merchant acquisition. The strategic use of AI, particularly in their Shop App, has driven traffic, engagement, and ultimately growth for the company.\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_shop with args: {\"query\": \"initial results of using AI\", \"page_numbers\": [\"7\"]}\n",
      "=== Function Output ===\n",
      "The initial results of using AI tools and models include sharper and more iterative feedback, enabling more precise analysis, delivering quicker signals, and allowing for faster identification of patterns to swiftly adapt and respond.\n",
      "=== LLM Response ===\n",
      "Shopify has implemented AI in their business to optimize marketing strategies, enhance customer acquisition, and improve customer engagement. Their AI-driven marketing systems have helped maximize returns on existing channels and explore new ones effectively. By leveraging data analytics, Shopify has identified successful channels and increased merchant acquisition. The strategic use of AI, particularly in their Shop App, has driven traffic, engagement, and growth for the company.\n",
      "\n",
      "The initial results of using AI tools and models at Shopify include sharper and more iterative feedback, enabling precise analysis, delivering quicker signals, and allowing for faster identification of patterns to adapt and respond swiftly.\n"
     ]
    }
   ],
   "source": [
    "# The agent can then choose the appropriate tools for each steps \n",
    "response = agent.query(\n",
    "    \"Tell me about how shopify uses AI in their business (please use original words and as detailed as possible),\"\n",
    "    \"and then tell me their initial results on using AI\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c00137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can chat/query about the LLM's reasoning process\n",
    "response = agent.chat(\n",
    "    \"Tell me about the tools you leverage to answer the above question.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eede70c",
   "metadata": {},
   "source": [
    "## 2. Setup an agent over more files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5ee34d-02ac-4537-ae20-7ef6c5767172",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tools for paper: transcripts/shop.pdf\n",
      "Getting tools for paper: transcripts/low.pdf\n"
     ]
    }
   ],
   "source": [
    "from utils import get_doc_tools\n",
    "\n",
    "paper_to_tools_dict = {}\n",
    "for name,filename in zip(file_name,file_path):\n",
    "  print(f\"Getting tools for paper: {filename}\")\n",
    "  vector_tool, summary_tool = get_doc_tools(filename,name)\n",
    "  paper_to_tools_dict[name] = [vector_tool, summary_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e35d52c",
   "metadata": {},
   "source": [
    "### Extend the Agent with Tool Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20154923-873e-4941-9a3a-4926ab5f9b8c",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_tools = [t for f in file_name for t in papers_to_tools_dict[f]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "671582f9-70d7-4a8f-b813-58b2a068ca72",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define an \"object\" index over these tools\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    all_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3929882-e9dc-46ca-b495-53e3ed60340e",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the \"retriever\" over the index with specified retrieval method\n",
    "obj_retriever = obj_index.as_retriever(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba9cfecd-fe14-4da8-b9ba-b3d485d98a03",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = obj_retriever.retrieve(\n",
    "    \"Tell me about the eval dataset used in self rag and crag\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c270ffbf-69c7-48ea-a028-9ba25221cde5",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMetadata(description='Use ONLY IF you want to get a holistic summary of MetaGPT. Do NOT use if you have specific questions over MetaGPT.', name='summary_tool_shop', fn_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, return_direct=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for the top 3 tools selected\n",
    "tools[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2deec1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\" \\\n",
    "You are an agent designed to answer queries over a set of given earnings call transcripts reports.\n",
    "Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cc0a0b6-9858-4348-9ae0-1cd4160f3fb7",
   "metadata": {
    "height": 268,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionCallingAgentWorker, AgentRunner\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Define the agentWorker and agentRunner\u001b[39;00m\n\u001b[1;32m      4\u001b[0m agent_worker \u001b[38;5;241m=\u001b[39m FunctionCallingAgentWorker\u001b[38;5;241m.\u001b[39mfrom_tools(\n\u001b[1;32m      5\u001b[0m     tool_retriever\u001b[38;5;241m=\u001b[39mobj_retriever,\n\u001b[0;32m----> 6\u001b[0m     llm\u001b[38;5;241m=\u001b[39m\u001b[43mllm\u001b[49m, \n\u001b[1;32m      7\u001b[0m     system_prompt\u001b[38;5;241m=\u001b[39msystem_message,\n\u001b[1;32m      8\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Initialize the AgentRunner with the agent worker\u001b[39;00m\n\u001b[1;32m     12\u001b[0m agent \u001b[38;5;241m=\u001b[39m AgentRunner(agent_worker)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker, AgentRunner\n",
    "\n",
    "# Define the agentWorker and agentRunner\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tool_retriever=obj_retriever,\n",
    "    llm=llm, \n",
    "    system_prompt=system_message,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Initialize the AgentRunner with the agent worker\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a250cf1a-e011-4994-bcca-4e0294f20864",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = agent.query(\n",
    "    \"Tell me about the evaluation dataset used \"\n",
    "    \"in self RAG against the dataset used in CRAG\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f011497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
