{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-document Agentic RAG using Llama-Index and Mistral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "llama-index\n",
    "llama-index-llms-huggingface\n",
    "llama-index-embeddings-fastembed\n",
    "fastembed\n",
    "Unstructured[md]\n",
    "chromadb\n",
    "llama-index-vector-stores-chroma\n",
    "llama-index-llms-groq\n",
    "einops\n",
    "accelerate\n",
    "sentence-transformers\n",
    "llama-index-llms-mistralai\n",
    "llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (0.10.65)\n",
      "Requirement already satisfied: llama-index-llms-huggingface in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.2.8)\n",
      "Requirement already satisfied: llama-index-embeddings-fastembed in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (0.1.7)\n",
      "Requirement already satisfied: fastembed in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (0.3.4)\n",
      "Requirement already satisfied: chromadb in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (0.5.5)\n",
      "Requirement already satisfied: llama-index-vector-stores-chroma in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (0.1.10)\n",
      "Requirement already satisfied: llama-index-llms-groq in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (0.1.4)\n",
      "Requirement already satisfied: einops in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (0.8.0)\n",
      "Requirement already satisfied: accelerate in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (0.33.0)\n",
      "Requirement already satisfied: sentence-transformers in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (3.0.1)\n",
      "Requirement already satisfied: llama-index-llms-mistralai in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (0.1.20)\n",
      "Requirement already satisfied: llama-index-llms-openai in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (0.1.29)\n",
      "Requirement already satisfied: Unstructured[md] in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (0.15.5)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index->-r requirements.txt (line 1)) (0.2.9)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index->-r requirements.txt (line 1)) (0.1.13)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.65 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index->-r requirements.txt (line 1)) (0.10.66)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index->-r requirements.txt (line 1)) (0.1.11)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.2.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index->-r requirements.txt (line 1)) (0.2.7)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index->-r requirements.txt (line 1)) (0.9.48.post2)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index->-r requirements.txt (line 1)) (0.1.9)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index->-r requirements.txt (line 1)) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index->-r requirements.txt (line 1)) (0.1.33)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.1.2 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index->-r requirements.txt (line 1)) (0.1.6)\n",
      "Requirement already satisfied: huggingface-hub<0.24.0,>=0.23.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index-llms-huggingface->-r requirements.txt (line 2)) (0.23.5)\n",
      "Requirement already satisfied: text-generation<0.8.0,>=0.7.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index-llms-huggingface->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index-llms-huggingface->-r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface->-r requirements.txt (line 2)) (4.44.0)\n",
      "Requirement already satisfied: PyStemmer<3.0.0,>=2.2.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from fastembed->-r requirements.txt (line 4)) (2.2.0.1)\n",
      "Requirement already satisfied: loguru<0.8.0,>=0.7.2 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from fastembed->-r requirements.txt (line 4)) (0.7.2)\n",
      "Requirement already satisfied: mmh3<5.0,>=4.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from fastembed->-r requirements.txt (line 4)) (4.1.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from fastembed->-r requirements.txt (line 4)) (1.26.4)\n",
      "Requirement already satisfied: onnx<2.0.0,>=1.15.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from fastembed->-r requirements.txt (line 4)) (1.16.2)\n",
      "Requirement already satisfied: onnxruntime<2.0.0,>=1.17.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from fastembed->-r requirements.txt (line 4)) (1.19.0)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from fastembed->-r requirements.txt (line 4)) (10.4.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from fastembed->-r requirements.txt (line 4)) (2.32.3)\n",
      "Requirement already satisfied: snowballstemmer<3.0.0,>=2.2.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from fastembed->-r requirements.txt (line 4)) (2.2.0)\n",
      "Requirement already satisfied: tokenizers<1.0,>=0.15 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from fastembed->-r requirements.txt (line 4)) (0.19.1)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.66 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from fastembed->-r requirements.txt (line 4)) (4.66.4)\n",
      "Requirement already satisfied: chardet in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from Unstructured[md]->-r requirements.txt (line 5)) (5.2.0)\n",
      "Requirement already satisfied: filetype in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from Unstructured[md]->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from Unstructured[md]->-r requirements.txt (line 5)) (0.4.27)\n",
      "Requirement already satisfied: lxml in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from Unstructured[md]->-r requirements.txt (line 5)) (5.2.2)\n",
      "Requirement already satisfied: nltk in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from Unstructured[md]->-r requirements.txt (line 5)) (3.8.1)\n",
      "Requirement already satisfied: tabulate in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from Unstructured[md]->-r requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from Unstructured[md]->-r requirements.txt (line 5)) (4.12.3)\n",
      "Requirement already satisfied: emoji in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from Unstructured[md]->-r requirements.txt (line 5)) (2.12.1)\n",
      "Requirement already satisfied: dataclasses-json in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from Unstructured[md]->-r requirements.txt (line 5)) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from Unstructured[md]->-r requirements.txt (line 5)) (2024.4.27)\n",
      "Requirement already satisfied: langdetect in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from Unstructured[md]->-r requirements.txt (line 5)) (1.0.9)\n",
      "Requirement already satisfied: rapidfuzz in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from Unstructured[md]->-r requirements.txt (line 5)) (3.9.6)\n",
      "Requirement already satisfied: backoff in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from Unstructured[md]->-r requirements.txt (line 5)) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from Unstructured[md]->-r requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: unstructured-client in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from Unstructured[md]->-r requirements.txt (line 5)) (0.25.5)\n",
      "Requirement already satisfied: wrapt in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from Unstructured[md]->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: psutil in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from Unstructured[md]->-r requirements.txt (line 5)) (6.0.0)\n",
      "Requirement already satisfied: markdown in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from Unstructured[md]->-r requirements.txt (line 5)) (3.7)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (1.2.1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (0.112.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 6)) (0.30.6)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (0.47b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (1.26.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (6.4.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (1.65.4)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (4.2.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (0.12.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (30.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (8.4.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (6.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (3.10.7)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 6)) (0.27.0)\n",
      "Requirement already satisfied: llama-index-llms-openai-like<0.2.0,>=0.1.3 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index-llms-groq->-r requirements.txt (line 8)) (0.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from accelerate->-r requirements.txt (line 10)) (24.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from accelerate->-r requirements.txt (line 10)) (0.4.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from sentence-transformers->-r requirements.txt (line 11)) (1.5.1)\n",
      "Requirement already satisfied: scipy in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from sentence-transformers->-r requirements.txt (line 11)) (1.14.0)\n",
      "Requirement already satisfied: mistralai>=1.0.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index-llms-mistralai->-r requirements.txt (line 12)) (1.0.1)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index-llms-openai->-r requirements.txt (line 13)) (1.40.8)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb->-r requirements.txt (line 6)) (0.38.2)\n",
      "Requirement already satisfied: anyio in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 6)) (4.4.0)\n",
      "Requirement already satisfied: certifi in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 6)) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 6)) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 6)) (3.7)\n",
      "Requirement already satisfied: sniffio in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb->-r requirements.txt (line 6)) (0.14.0)\n",
      "Requirement already satisfied: filelock in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface->-r requirements.txt (line 2)) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface->-r requirements.txt (line 2)) (2024.6.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (2.31.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (2.2.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.65->llama-index->-r requirements.txt (line 1)) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index->-r requirements.txt (line 1)) (3.9.5)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index->-r requirements.txt (line 1)) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index->-r requirements.txt (line 1)) (1.0.8)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index->-r requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index->-r requirements.txt (line 1)) (3.3)\n",
      "Requirement already satisfied: pandas in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index->-r requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: llama-cloud>=0.0.11 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index->-r requirements.txt (line 1)) (0.0.13)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index->-r requirements.txt (line 1)) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index->-r requirements.txt (line 1)) (0.0.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from beautifulsoup4->Unstructured[md]->-r requirements.txt (line 5)) (2.5)\n",
      "Requirement already satisfied: llama-parse>=0.4.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from llama-index-readers-llama-parse>=0.1.2->llama-index->-r requirements.txt (line 1)) (0.4.9)\n",
      "Requirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from mistralai>=1.0.0->llama-index-llms-mistralai->-r requirements.txt (line 12)) (1.0.6)\n",
      "Requirement already satisfied: click in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from nltk->Unstructured[md]->-r requirements.txt (line 5)) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from nltk->Unstructured[md]->-r requirements.txt (line 5)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from nltk->Unstructured[md]->-r requirements.txt (line 5)) (2024.7.24)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from onnx<2.0.0,>=1.15.0->fastembed->-r requirements.txt (line 4)) (4.25.4)\n",
      "Requirement already satisfied: coloredlogs in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 4)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 4)) (24.3.25)\n",
      "Requirement already satisfied: sympy in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 4)) (1.13.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai->-r requirements.txt (line 13)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai->-r requirements.txt (line 13)) (0.5.0)\n",
      "Requirement already satisfied: importlib-metadata<=8.0.0,>=6.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 6)) (8.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 6)) (1.63.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.26.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 6)) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.26.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 6)) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.47b0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 6)) (0.47b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.47b0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 6)) (0.47b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.47b0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 6)) (0.47b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.47b0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 6)) (0.47b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 6)) (70.1.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 6)) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb->-r requirements.txt (line 6)) (1.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from pydantic>=1.9->chromadb->-r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from pydantic>=1.9->chromadb->-r requirements.txt (line 6)) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from requests<3.0,>=2.31->fastembed->-r requirements.txt (line 4)) (3.3.2)\n",
      "Requirement already satisfied: jinja2 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface->-r requirements.txt (line 2)) (3.1.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 6)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 6)) (13.7.1)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 6)) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 6)) (0.20.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 6)) (0.23.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 6)) (12.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from dataclasses-json->Unstructured[md]->-r requirements.txt (line 5)) (3.21.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 11)) (3.5.0)\n",
      "Requirement already satisfied: deepdiff>=6.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from unstructured-client->Unstructured[md]->-r requirements.txt (line 5)) (7.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from unstructured-client->Unstructured[md]->-r requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from unstructured-client->Unstructured[md]->-r requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index->-r requirements.txt (line 1)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index->-r requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index->-r requirements.txt (line 1)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index->-r requirements.txt (line 1)) (1.9.4)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from deepdiff>=6.0->unstructured-client->Unstructured[md]->-r requirements.txt (line 5)) (4.1.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 6)) (3.19.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb->-r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb->-r requirements.txt (line 6)) (2.18.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.65->llama-index->-r requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 4)) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface->-r requirements.txt (line 2)) (2.1.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.65->llama-index->-r requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.65->llama-index->-r requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from sympy->onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb->-r requirements.txt (line 6)) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /Users/sliu/miniconda3/envs/ml4t/lib/python3.12/site-packages (3.2)\n",
      "zsh:1: command not found: wget\n"
     ]
    }
   ],
   "source": [
    "!pip install wget\n",
    "import wget\n",
    "\n",
    "!wget --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download files to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n",
      "zsh:1: command not found: wget\n",
      "zsh:1: command not found: wget\n",
      "zsh:1: command not found: wget\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "\n",
    "!mkdir -p data\n",
    "# Download the files\n",
    "!wget \"https://arxiv.org/pdf/1810.04805.pdf\" -O data/BERT_arxiv.pdf\n",
    "!wget \"https://arxiv.org/pdf/2005.11401.pdf\" -O data/RAG_arxiv.pdf\n",
    "!wget \"https://arxiv.org/pdf/2310.11511.pdf\" -O data/self_rag_arxiv.pdf\n",
    "!wget \"https://arxiv.org/pdf/2401.15884.pdf\" -O data/crag_arxiv.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader,VectorStoreIndex,SummaryIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.tools import FunctionTool,QueryEngineTool\n",
    "from llama_index.core.vector_stores import MetadataFilters,FilterCondition\n",
    "from typing import List,Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n",
      "Document Metadata: {'page_label': '1', 'file_name': 'situationalawareness.pdf', 'file_path': 'data/situationalawareness.pdf', 'file_type': 'application/pdf', 'file_size': 21371840, 'creation_date': '2024-08-18', 'last_modified_date': '2024-08-18'}\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(input_files = ['data/situationalawareness.pdf']).load_data()\n",
    "print(len(documents))\n",
    "print(f\"Document Metadata: {documents[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the documents into chunks/nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of nodes : 165\n",
      "get the content for node 0 :page_label: 1\n",
      "file_name: situationalawareness.pdf\n",
      "file_path: data/situationalawareness.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 21371840\n",
      "creation_date: 2024-08-18\n",
      "last_modified_date: 2024-08-18\n",
      "\n",
      "Leopold Aschenbrenner\n",
      "S I T U AT I O N A L AWA R E N E S S\n",
      "The Decade Ahead\n",
      "JUNE 2024\n"
     ]
    }
   ],
   "source": [
    "splitter = SentenceSplitter(chunk_size=1024,chunk_overlap=100)\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "print(f\"Length of nodes : {len(nodes)}\")\n",
    "print(f\"get the content for node 0 :{nodes[0].get_content(metadata_mode='all')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantitate the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db_mistral\")\n",
    "chroma_collection = db.get_or_create_collection(\"multidocument-agent\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f5473c471045bc85da40dffa65d6d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9335ceb743904293a32473c7d083d03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/706 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2702ec84e647baae145fad2253c9fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0ebbf648a7464cbe1220734055e2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12068dfff0f4ff8ab8e02ecaed63672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bb74a0281c4f75865ce2a3bf56371a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_optimized.onnx:   0%|          | 0.00/66.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "from llama_index.core import Settings\n",
    "#\n",
    "embed_model = FastEmbedEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "#\n",
    "Settings.embed_model = embed_model\n",
    "#\n",
    "Settings.chunk_size = 1024\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# Retrieve OpenAI API key from environment variable\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if api_key is None:\n",
    "    raise ValueError(\"OpenAI API key not found in environment variables.\")\n",
    "\n",
    "# Set the OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "# Instantiate the OpenAI model\n",
    "llm = OpenAI(model=\"gpt-4\")  # Use the appropriate model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate Vectorstore\n",
    "name = \"nuclear-series-final\"\n",
    "vector_index = VectorStoreIndex(nodes,storage_context=storage_context)\n",
    "vector_index.storage_context.vector_store.persist(persist_path=\"/content/chroma_db\")\n",
    "#\n",
    "# Define Vectorstore Autoretrieval tool\n",
    "def vector_query(query:str,page_numbers:Optional[List[str]]=None)->str:\n",
    "  '''\n",
    "  perform vector search over index on\n",
    "  query(str): query string needs to be embedded\n",
    "  page_numbers(List[str]): list of page numbers to be retrieved,\n",
    "                          leave blank if we want to perform a vector search over all pages\n",
    "  '''\n",
    "  page_numbers = page_numbers or []\n",
    "  metadata_dict = [{\"key\":'page_label',\"value\":p} for p in page_numbers]\n",
    "  #\n",
    "  query_engine = vector_index.as_query_engine(similarity_top_k =2,\n",
    "                                              filters = MetadataFilters.from_dicts(metadata_dict,\n",
    "                                                                                    condition=FilterCondition.OR)\n",
    "                                              )\n",
    "  #\n",
    "  response = query_engine.query(query)\n",
    "  return response\n",
    "#\n",
    "#llamiondex FunctionTool wraps any python function we feed it\n",
    "vector_query_tool = FunctionTool.from_defaults(name=f\"vector_tool_{name}\",\n",
    "                                              fn=vector_query)\n",
    "# Prepare Summary Tool\n",
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(response_mode=\"tree_summarize\",\n",
    "                                                      se_async=True,)\n",
    "summary_query_tool = QueryEngineTool.from_defaults(name=f\"summary_tool_{name}\",\n",
    "                                                    query_engine=summary_query_engine,\n",
    "                                                  description=(\"Use ONLY IF you want to get a holistic summary of the documents.\"\n",
    "                                              \"DO NOT USE if you have specified questions over the documents.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected at least one tool call, but got 0 tool calls.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_and_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvector_query_tool\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSummarize the contentin this document\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4t/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    253\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[1;32m    254\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    257\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[1;32m    258\u001b[0m )\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4t/lib/python3.12/site-packages/llama_index/core/llms/function_calling.py:190\u001b[0m, in \u001b[0;36mFunctionCallingLLM.predict_and_call\u001b[0;34m(self, tools, user_msg, chat_history, verbose, allow_parallel_tool_calls, error_on_no_tool_call, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpredict_and_call(\n\u001b[1;32m    175\u001b[0m         tools,\n\u001b[1;32m    176\u001b[0m         user_msg\u001b[38;5;241m=\u001b[39muser_msg,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    182\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_with_tools(\n\u001b[1;32m    183\u001b[0m     tools,\n\u001b[1;32m    184\u001b[0m     user_msg\u001b[38;5;241m=\u001b[39muser_msg,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    189\u001b[0m )\n\u001b[0;32m--> 190\u001b[0m tool_calls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tool_calls_from_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_no_tool_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_on_no_tool_call\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m tool_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    194\u001b[0m     call_tool_with_selection(tool_call, tools, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tool_call \u001b[38;5;129;01min\u001b[39;00m tool_calls\n\u001b[1;32m    196\u001b[0m ]\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_parallel_tool_calls:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4t/lib/python3.12/site-packages/llama_index/llms/openai/base.py:901\u001b[0m, in \u001b[0;36mOpenAI.get_tool_calls_from_response\u001b[0;34m(self, response, error_on_no_tool_call, **kwargs)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tool_calls) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error_on_no_tool_call:\n\u001b[0;32m--> 901\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    902\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected at least one tool call, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(tool_calls)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tool calls.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    903\u001b[0m         )\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "\u001b[0;31mValueError\u001b[0m: Expected at least one tool call, but got 0 tool calls."
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call([vector_query_tool],\n",
    "                                \"Summarize the contentin this document\",\n",
    "                                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_tools(file_path:str,name:str)->str:\n",
    "  '''\n",
    "  get vector query and sumnmary query tools from a document\n",
    "  '''\n",
    "  #load documents\n",
    "  documents = SimpleDirectoryReader(input_files = [file_path]).load_data()\n",
    "  print(f\"length of nodes\")\n",
    "  splitter = SentenceSplitter(chunk_size=1024,chunk_overlap=100)\n",
    "  nodes = splitter.get_nodes_from_documents(documents)\n",
    "  print(f\"Length of nodes : {len(nodes)}\")\n",
    "  #instantiate Vectorstore\n",
    "  vector_index = VectorStoreIndex(nodes,storage_context=storage_context)\n",
    "  vector_index.storage_context.vector_store.persist(persist_path=\"/content/chroma_db\")\n",
    "  #\n",
    "  # Define Vectorstore Autoretrieval tool\n",
    "  def vector_query(query:str,page_numbers:Optional[List[str]]=None)->str:\n",
    "    '''\n",
    "    perform vector search over index on\n",
    "    query(str): query string needs to be embedded\n",
    "    page_numbers(List[str]): list of page numbers to be retrieved,\n",
    "                            leave blank if we want to perform a vector search over all pages\n",
    "    '''\n",
    "    page_numbers = page_numbers or []\n",
    "    metadata_dict = [{\"key\":'page_label',\"value\":p} for p in page_numbers]\n",
    "    #\n",
    "    query_engine = vector_index.as_query_engine(similarity_top_k =2,\n",
    "                                                filters = MetadataFilters.from_dicts(metadata_dict,\n",
    "                                                                                     condition=FilterCondition.OR)\n",
    "                                                )\n",
    "    #\n",
    "    response = query_engine.query(query)\n",
    "    return response\n",
    "  #\n",
    "  #llamiondex FunctionTool wraps any python function we feed it\n",
    "  vector_query_tool = FunctionTool.from_defaults(name=f\"vector_tool_{name}\",\n",
    "                                                fn=vector_query)\n",
    "  # Prepare Summary Tool\n",
    "  summary_index = SummaryIndex(nodes)\n",
    "  summary_query_engine = summary_index.as_query_engine(response_mode=\"tree_summarize\",\n",
    "                                                       se_async=True,)\n",
    "  summary_query_tool = QueryEngineTool.from_defaults(name=f\"summary_tool_{name}\",\n",
    "                                                     query_engine=summary_query_engine,\n",
    "                                                    description=(\"Use ONLY IF you want to get a holistic summary of the documents.\"\n",
    "                                                \"DO NOT USE if you have specified questions over the documents.\"))\n",
    "  return vector_query_tool,summary_query_tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['situationalawareness']\n",
      "['data/situationalawareness.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "root_path = \"data\"\n",
    "file_name = []\n",
    "file_path = []\n",
    "for file in os.listdir(root_path):\n",
    "  if file.endswith(\".pdf\"):\n",
    "    file_name.append(file.split(\".\")[0])\n",
    "    file_path.append(os.path.join(root_path,file))\n",
    "#\n",
    "print(file_name)\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of nodes\n",
      "Length of nodes : 165\n"
     ]
    }
   ],
   "source": [
    "papers_to_tools_dict = {}\n",
    "for name,filename in zip(file_name,file_path):\n",
    "  vector_query_tool,summary_query_tool = get_doc_tools(filename,name)\n",
    "  papers_to_tools_dict[name] = [vector_query_tool,summary_query_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<llama_index.core.tools.function_tool.FunctionTool at 0x148d6a3f0>,\n",
       " <llama_index.core.tools.query_engine.QueryEngineTool at 0x1514d81d0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tools = [t for f in file_name for t in papers_to_tools_dict[f]]\n",
    "initial_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "#\n",
    "obj_index = ObjectIndex.from_objects(initial_tools,index_cls=VectorStoreIndex)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolMetadata(description='Use ONLY IF you want to get a holistic summary of the documents.DO NOT USE if you have specified questions over the documents.', name='summary_tool_situationalawareness', fn_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, return_direct=False)\n",
      "ToolMetadata(description='vector_tool_situationalawareness(query: str, page_numbers: Optional[List[str]] = None) -> str\\n\\n    perform vector search over index on\\n    query(str): query string needs to be embedded\\n    page_numbers(List[str]): list of page numbers to be retrieved,\\n                            leave blank if we want to perform a vector search over all pages\\n    ', name='vector_tool_situationalawareness', fn_schema=<class 'pydantic.v1.main.vector_tool_situationalawareness'>, return_direct=False)\n"
     ]
    }
   ],
   "source": [
    "obj_retriever = obj_index.as_retriever(similarity_top_k=2)\n",
    "tools = obj_retriever.retrieve(\"summary of the nuclear industry\")\n",
    "#\n",
    "print(tools[0].metadata)\n",
    "print(tools[1].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "#\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(tool_retriever=obj_retriever,\n",
    "                                                     llm=llm,\n",
    "                                                     system_prompt=\"\"\"You are an agent designed to answer queries over a set of given documents.\n",
    "                                                     Please always use the tools provided to answer a question.Do not rely on prior knowledge.\"\"\",\n",
    "                                                     verbose=True)\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Please summarize this document\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_situationalawareness with args: {\"input\": \"document\"}\n",
      "=== Function Output ===\n",
      "The document extensively discusses the advancements in AI technology, particularly focusing on language models like GPT-2, GPT-3, and GPT-4. It highlights the significant progress made in algorithmic efficiencies, compute scaling, and \"unhobbling\" techniques to enhance the capabilities of these models. The text also delves into the potential future developments, such as enabling models to use computers, improving test-time compute capabilities, and transitioning from chatbots to more advanced agents or drop-in remote workers. The document predicts another substantial leap in AI capabilities by the end of 2027, building upon the advancements seen from GPT-2 to GPT-4.\n",
      "=== LLM Response ===\n",
      "The document discusses the advancements in AI technology, particularly focusing on language models like GPT-2, GPT-3, and GPT-4. It highlights the significant progress made in algorithmic efficiencies, compute scaling, and \"unhobbling\" techniques to enhance the capabilities of these models. The text also delves into the potential future developments, such as enabling models to use computers, improving test-time compute capabilities, and transitioning from chatbots to more advanced agents or drop-in remote workers. The document predicts another substantial leap in AI capabilities by the end of 2027, building upon the advancements seen from GPT-2 to GPT-4.\n",
      "The document discusses the advancements in AI technology, particularly focusing on language models like GPT-2, GPT-3, and GPT-4. It highlights the significant progress made in algorithmic efficiencies, compute scaling, and \"unhobbling\" techniques to enhance the capabilities of these models. The text also delves into the potential future developments, such as enabling models to use computers, improving test-time compute capabilities, and transitioning from chatbots to more advanced agents or drop-in remote workers. The document predicts another substantial leap in AI capabilities by the end of 2027, building upon the advancements seen from GPT-2 to GPT-4.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "response = agent.query(\"Please summarize this document\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What about UBI?\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_situationalawareness with args: {\"query\": \"UBI\"}\n",
      "=== Function Output ===\n",
      "Universal Basic Income (UBI) is a concept that involves providing all citizens with a regular, unconditional sum of money, without any means test or work requirement.\n",
      "=== LLM Response ===\n",
      "Universal Basic Income (UBI) is a concept that involves providing all citizens with a regular, unconditional sum of money, without any means test or work requirement.\n",
      "Universal Basic Income (UBI) is a concept that involves providing all citizens with a regular, unconditional sum of money, without any means test or work requirement.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\"What about UBI?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
